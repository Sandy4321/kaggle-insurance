{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import feature_generator\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetBestModel(modelsToUse):\n",
    "    \n",
    "    K = 3\n",
    "    kf = KFold(len(dfTrain), K)\n",
    "    \n",
    "    bestQwk = -1\n",
    "    bestCutPoints = None\n",
    "    bestModel = None\n",
    "    \n",
    "    meanTestQwk = 0\n",
    "    meanTrainQwk = 0\n",
    "    num = 1\n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        frames = [pd.read_csv('fold%s.csv' % str(i)) for i in range(1, K+1) if i != num  ]\n",
    "        trainModelPredictions = pd.concat(frames)  \n",
    "        \n",
    "        xTrain = trainModelPredictions[modelsToUse].values\n",
    "        yTrain = dfTrain.iloc[train_index]['Response']\n",
    "                \n",
    "        stackingModel = LinearRegression()\n",
    "        stackingModel.fit(xTrain, yTrain)\n",
    "\n",
    "        xTest = pd.read_csv('fold%s.csv' % str(num))[modelsToUse].values\n",
    "        yTest = dfTrain.iloc[test_index]['Response']\n",
    "        \n",
    "        trainPredictions = stackingModel.predict(xTrain)\n",
    "        predictions = stackingModel.predict(xTest)\n",
    "\n",
    "#         cpo = CutPointOptimizer(trainPredictions, yTrain)\n",
    "#         cutPoints = optimize.fmin(cpo.qwk, initialCutPoints)\n",
    " \n",
    "#         trainPredictions = np.searchsorted(cutPoints, trainPredictions) + 1   \n",
    "#         predictions = np.searchsorted(cutPoints, predictions) + 1   \n",
    "    \n",
    "#         noStack = quadratic_weighted_kappa.quadratic_weighted_kappa(xTest, yTest)\n",
    "        testQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, yTest)\n",
    "        trainQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, yTrain)\n",
    "\n",
    "#         print \"No Stack: %s\\n\" % noStack\n",
    "        print \"TestQWK: %s\\n\" % testQwk\n",
    "        print \"Train QWK: %s\\n\" % trainQwk\n",
    "        \n",
    "        meanTestQwk += (testQwk / K)\n",
    "        meanTrainQwk += (trainQwk / K)\n",
    "        \n",
    "        if testQwk > bestQwk:\n",
    "            bestQwk= testQwk\n",
    "            bestModel = stackingModel  \n",
    "#             bestCutPoints = cutPoints\n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    return bestModel, bestCutPoints, meanTestQwk, meanTrainQwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Stack: 0.646270626345\n",
      "\n",
      "TestQWK: 0.585221211541\n",
      "\n",
      "Train QWK: 0.590117036476\n",
      "\n",
      "No Stack: 0.639844414905\n",
      "\n",
      "TestQWK: 0.589867138885\n",
      "\n",
      "Train QWK: 0.58775413105\n",
      "\n",
      "No Stack: 0.649820597261\n",
      "\n",
      "TestQWK: 0.562309941777\n",
      "\n",
      "Train QWK: 0.562594123404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelsToUse = ['LogisticRegression', 'Keras100/50Layers6Epochs', 'XGBoost', 'BaggingDescisionTrees_n_estimators=20']\n",
    "#not using BaggingLinearRegression_n_estimators=10' currently\n",
    "# modelsToUse = ['XGBoost']\n",
    "bestStackingModel, bestCutPoints, _, _ = GetBestModel(modelsToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WritePredictionsToFile(stackingModel, cutPoints, modelsToUse, dfTest, fileName):\n",
    "        X = pd.read_csv('testPredictions.csv')[modelsToUse].values\n",
    "        predictions = np.searchsorted(cutPoints, stackingModel.predict(X)) + 1  \n",
    "        predDf = pd.DataFrame()\n",
    "        predDf['Id'] = dfTest['Id']\n",
    "        predDf['Response'] = predictions\n",
    "        print predictions\n",
    "        predDf.to_csv(path_or_buf=fileName, columns=['Id', 'Response'], index=False, header=['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 7 ..., 4 1 3]\n"
     ]
    }
   ],
   "source": [
    "WritePredictionsToFile(bestStackingModel, bestCutPoints, modelsToUse, dfTest, 'cutPointsStacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingDescisionTrees_n_estimators=20, BaggingLinearRegression_n_estimators=10, (0.83540238769065311, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, LogisticRegression, (0.71984046254126033, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoost, (0.90723913925647082, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostLinear, (0.89283334232602007, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras100/50Layers6Epochs, (0.82664006360441522, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, LogisticRegression, (0.79807322775143286, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoost, (0.91090304621084206, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostLinear, (0.88238511312863521, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras100/50Layers6Epochs, (0.93524853166482902, 0.0)\n",
      "LogisticRegression, XGBoost, (0.78100656315711203, 0.0)\n",
      "LogisticRegression, XGBoostLinear, (0.76372491674735887, 0.0)\n",
      "LogisticRegression, Keras100/50Layers6Epochs, (0.84257605054523654, 0.0)\n",
      "XGBoost, XGBoostLinear, (0.95569593974586808, 0.0)\n",
      "XGBoost, Keras100/50Layers6Epochs, (0.89115436397849379, 0.0)\n",
      "XGBoostLinear, Keras100/50Layers6Epochs, (0.87057402793169003, 0.0)\n"
     ]
    }
   ],
   "source": [
    "fold1 = pd.read_csv('fold1.csv')\n",
    "\n",
    "for i in range(len(fold1.columns)):\n",
    "    for j in range(i + 1, len(fold1.columns)):        \n",
    "        print \"%s, %s, %s\" % (fold1.columns[i], fold1.columns[j], pearsonr(fold1[fold1.columns[i]], fold1[fold1.columns[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5  2.5  3.5  4.5  5.5  6.5  7.5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def qwk(cutPoints):\n",
    "#     transformedPredictions = np.searchsorted(cutPoints, predicted) + 1            \n",
    "#     return -1 * quadratic_weighted_kappa.quadratic_weighted_kappa(transformedPredictions, actual)\n",
    "\n",
    "initialCutPoints = np.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5])\n",
    "print initialCutPoints\n",
    "# optimize.fmin(test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
