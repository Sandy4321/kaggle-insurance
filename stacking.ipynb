{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import feature_generator\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import optimize\n",
    "from XgBoost import XGBoostModel\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Info_2\n",
      "Product_Info_3\n",
      "Employment_Info_2\n",
      "InsuredInfo_3\n",
      "Medical_History_2\n",
      "Medical_History_10\n",
      "Scaling...\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')    \n",
    "\n",
    "train, _, labels = feature_generator.GetFeatures(dfTrain, dfTest, 10, True)\n",
    "metaFeatures = train.columns\n",
    "\n",
    "#GetFeatures currently modifies dfTest, need to re-create them\n",
    "dfTest = pd.read_csv('test.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StackingResults:\n",
    "    \n",
    "    def __init__(self, stackingModel, cutPoints, qwk):\n",
    "        self.stackingModel = stackingModel\n",
    "        self.cutPoints = cutPoints\n",
    "        self.qwk = qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateStackingResults(xTrain, yTrain, xTest, yTest):\n",
    "    stackingModel = LinearRegression()\n",
    "    stackingModel.fit(xTrain, yTrain)\n",
    "\n",
    "    trainPredictions = stackingModel.predict(xTrain)\n",
    "    predictions = stackingModel.predict(xTest)\n",
    "\n",
    "    cpo = CutPointOptimizer(trainPredictions, yTrain)\n",
    "    cutPoints = optimize.fmin(cpo.qwk, initialCutPoints)\n",
    "\n",
    "    trainPredictions = np.searchsorted(cutPoints, trainPredictions) + 1   \n",
    "    predictions = np.searchsorted(cutPoints, predictions) + 1   \n",
    "\n",
    "    testQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, yTest)\n",
    "    trainQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, yTrain)\n",
    " \n",
    "    print \"Test QWK: %s\\n\" % testQwk\n",
    "    print \"Train QWK: %s\\n\" % trainQwk\n",
    "    \n",
    "    return stackingModel, cutPoints, predictions, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetBestModel(modelsToUse, metaFeatures):\n",
    "    \n",
    "    K = 3\n",
    "    kf = KFold(len(train), K)\n",
    "    indices = [indices for indices in kf]\n",
    "    train_indices = [index[0] for index in indices]\n",
    "    test_indices = [index[1] for index in indices]\n",
    "        \n",
    "    meanTestQwk = 0\n",
    "    meanTrainQwk = 0\n",
    "    num = 1\n",
    "    resultList = list()\n",
    "\n",
    "    for i in range(1, K+1):\n",
    "        \n",
    "        fold = pd.read_csv('fold%s.csv' % str(i))\n",
    "    \n",
    "        features = list(modelsToUse)\n",
    "#         features = list()\n",
    "#         for model in modelsToUse:\n",
    "#             for metaFeature in metaFeatures:\n",
    "#                 feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "#                 features.append(feature)\n",
    "#                 fold[feature] = fold[model].values * train.iloc[test_indices[i-1]][metaFeature].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(fold[features], labels.iloc[test_indices[i-1]].values, test_size=0.20, random_state=0)\n",
    "        stackingModel, cutPoints, predictions, YTest = calculateStackingResults(X_train, y_train, X_test, y_test)        \n",
    "        overallTestQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, YTest)\n",
    "        \n",
    "        result = StackingResults(stackingModel, cutPoints, overallTestQwk) \n",
    "        resultList.append(result)    \n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CutPointOptimizer:\n",
    "    \n",
    "    def __init__(self, predicted, actual):\n",
    "        self.predicted = predicted\n",
    "        self.actual = actual\n",
    "\n",
    "    def qwk(self, cutPoints):\n",
    "        transformedPredictions = np.searchsorted(cutPoints, self.predicted) + 1            \n",
    "        return -1 * quadratic_weighted_kappa.quadratic_weighted_kappa(transformedPredictions, self.actual)\n",
    "\n",
    "initialCutPoints = np.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.650693\n",
      "         Iterations: 152\n",
      "         Function evaluations: 279\n",
      "Test QWK: 0.659732942059\n",
      "\n",
      "Train QWK: 0.650692721682\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.650657\n",
      "         Iterations: 99\n",
      "         Function evaluations: 233\n",
      "Test QWK: 0.634788092132\n",
      "\n",
      "Train QWK: 0.650656748163\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.662052\n",
      "         Iterations: 127\n",
      "         Function evaluations: 270\n",
      "Test QWK: 0.683412667776\n",
      "\n",
      "Train QWK: 0.662052058005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelsToUse = ['Keras', 'LogisticRegression', 'XGBoostRegLin', 'BaggingDescisionTrees_n_estimators=20', 'BaggingDescisionTreeClassifiers_n_estimators=20']\n",
    "# modelsToUse = ['XGBoostRegLin']\n",
    "#not using BaggingLinearRegression_n_estimators=10' currently\n",
    "# modelsToUse = ['Keras']\n",
    "# bestStackingModel, bestCutPoints, bestFold, _, _ = \n",
    "results = GetBestModel(modelsToUse, metaFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WritePredictionsToFile(results, modelsToUse, dfTest, fileName):\n",
    "               \n",
    "        predictions = np.zeros(len(dfTest))\n",
    "        \n",
    "        for i in range(1, len(results)+1):\n",
    "            X = pd.read_csv('testPredictions%s.csv' % str(i))[modelsToUse]\n",
    "            result = results[i-1]\n",
    "            print result.qwk\n",
    "            predictions += result.qwk * (np.searchsorted(result.cutPoints, result.stackingModel.predict(X)) + 1)\n",
    "            \n",
    "        totalWeight = np.sum([result.qwk for result in results])\n",
    "        predictions /= totalWeight\n",
    "        print predictions\n",
    "        predictions = np.round(predictions).astype(int)\n",
    "            \n",
    "        \n",
    "        predDf = pd.DataFrame()\n",
    "        predDf['Id'] = dfTest['Id']\n",
    "        predDf['Response'] = predictions\n",
    "        print predDf['Response'].values\n",
    "        predDf.to_csv(path_or_buf=fileName, columns=['Id', 'Response'], index=False, header=['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664805689465\n",
      "0.642602219973\n",
      "0.681422599368\n",
      "[ 2.32310557  6.          6.34262477 ...,  3.67689443  2.          2.34262477]\n",
      "[2 6 6 ..., 4 2 2]\n"
     ]
    }
   ],
   "source": [
    "WritePredictionsToFile(results, modelsToUse, dfTest, 'cutPointsStacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingDescisionTrees_n_estimators=20, BaggingLinearRegression_n_estimators=10, (0.82723223060018414, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, LogisticRegression, (0.71672697762552096, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoost, (0.90545269754757352, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostLinear, (0.82816721211796251, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras100/50Layers6Epochs, (0.81860775406944197, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras, (0.81700780178490495, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Index, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, IndexNum, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, LinXGBoost, (0.9073296629252775, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostKappa, (0.67522197855644062, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostRegLin, (0.91606803512950197, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, BaggingDescisionTreeClassifiers_n_estimators=20, (0.74292659153361496, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, LogisticRegression, (0.79257557312551052, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoost, (0.904850243234953, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostLinear, (0.99913140910352671, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras100/50Layers6Epochs, (0.92229682653105571, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras, (0.92010697919516937, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Index, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, IndexNum, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, LinXGBoost, (0.91019079106813661, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostKappa, (0.75564854859506869, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostRegLin, (0.90953350761334073, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68168961307299947, 0.0)\n",
      "LogisticRegression, XGBoost, (0.78209242227757947, 0.0)\n",
      "LogisticRegression, XGBoostLinear, (0.79283882656263416, 0.0)\n",
      "LogisticRegression, Keras100/50Layers6Epochs, (0.833530881516099, 0.0)\n",
      "LogisticRegression, Keras, (0.83357685317985819, 0.0)\n",
      "LogisticRegression, Index, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, IndexNum, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, LinXGBoost, (0.78290495298299478, 0.0)\n",
      "LogisticRegression, XGBoostKappa, (0.64366009561307713, 0.0)\n",
      "LogisticRegression, XGBoostRegLin, (0.78317345118762194, 0.0)\n",
      "LogisticRegression, BaggingDescisionTreeClassifiers_n_estimators=20, (0.61175842801347102, 0.0)\n",
      "XGBoost, XGBoostLinear, (0.90522784991976157, 0.0)\n",
      "XGBoost, Keras100/50Layers6Epochs, (0.88413515329574521, 0.0)\n",
      "XGBoost, Keras, (0.88171007365918852, 0.0)\n",
      "XGBoost, Index, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, IndexNum, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, LinXGBoost, (0.97609232514314026, 0.0)\n",
      "XGBoost, XGBoostKappa, (0.72140912158718817, 0.0)\n",
      "XGBoost, XGBoostRegLin, (0.97866581828483745, 0.0)\n",
      "XGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.73938416009873598, 0.0)\n",
      "XGBoostLinear, Keras100/50Layers6Epochs, (0.92278196779987209, 0.0)\n",
      "XGBoostLinear, Keras, (0.92073778661946493, 0.0)\n",
      "XGBoostLinear, Index, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, IndexNum, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, LinXGBoost, (0.91064005259907876, 0.0)\n",
      "XGBoostLinear, XGBoostKappa, (0.75595071266566749, 0.0)\n",
      "XGBoostLinear, XGBoostRegLin, (0.9100829960546285, 0.0)\n",
      "XGBoostLinear, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68283714571775789, 0.0)\n",
      "Keras100/50Layers6Epochs, Keras, (0.97983753409734264, 0.0)\n",
      "Keras100/50Layers6Epochs, Index, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, IndexNum, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, LinXGBoost, (0.88849761282823647, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostKappa, (0.72858524888847731, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostRegLin, (0.88935305062642545, 0.0)\n",
      "Keras100/50Layers6Epochs, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68761741035478674, 0.0)\n",
      "Keras, Index, (0.0052458432147417938, 0.46051311918970927)\n",
      "Keras, IndexNum, (0.0052458432147417938, 0.46051311918970927)\n",
      "Keras, LinXGBoost, (0.88665186404672836, 0.0)\n",
      "Keras, XGBoostKappa, (0.71584158281884491, 0.0)\n",
      "Keras, XGBoostRegLin, (0.88742191515977742, 0.0)\n",
      "Keras, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68962923444072199, 0.0)\n",
      "Index, IndexNum, (1.0, 0.0)\n",
      "Index, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "Index, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "Index, XGBoostRegLin, (0.0034977943473489693, 0.62266339790674163)\n",
      "Index, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0083909695130439613, 0.23780880957531433)\n",
      "IndexNum, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "IndexNum, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "IndexNum, XGBoostRegLin, (0.0034977943473489693, 0.62266339790674163)\n",
      "IndexNum, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0083909695130439613, 0.23780880957531433)\n",
      "LinXGBoost, XGBoostKappa, (0.71681602052852855, 0.0)\n",
      "LinXGBoost, XGBoostRegLin, (0.98736729585750505, 0.0)\n",
      "LinXGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.74589105708046266, 0.0)\n",
      "XGBoostKappa, XGBoostRegLin, (0.72189611233226181, 0.0)\n",
      "XGBoostKappa, BaggingDescisionTreeClassifiers_n_estimators=20, (0.55518448655116126, 0.0)\n",
      "XGBoostRegLin, BaggingDescisionTreeClassifiers_n_estimators=20, (0.75098054134586678, 0.0)\n"
     ]
    }
   ],
   "source": [
    "fold1 = pd.read_csv('fold1.csv')\n",
    "\n",
    "for i in range(len(fold1.columns)):\n",
    "    for j in range(i + 1, len(fold1.columns)):        \n",
    "        print \"%s, %s, %s\" % (fold1.columns[i], fold1.columns[j], pearsonr(fold1[fold1.columns[i]], fold1[fold1.columns[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.85559797287\n",
      "0.641791045\n",
      "0.313432836\n",
      "5.04165243211\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "num = 1\n",
    "frames = [pd.read_csv('fold%s.csv' % str(i)) for i in range(1, K+1) if i != num  ]\n",
    "testModelPredictions = pd.read_csv('fold%s.csv' % str(num))\n",
    "\n",
    "features = list()\n",
    "for model in modelsToUse:\n",
    "    for metaFeature in metaFeatures:\n",
    "        feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "        features.append(feature)\n",
    "        testModelPredictions[feature] = testModelPredictions[model] * dfTrain[metaFeature]\n",
    "        print foldDf[model][0]\n",
    "        print dfTrain[metaFeature][0]\n",
    "        print dfTrain[metaFeature][20000]\n",
    "        print testModelPredictions[feature][0]\n",
    "#         print testModelPredictions[feature][20000]\n",
    "#         print foldDf[model]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
