{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import feature_generator\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import optimize\n",
    "from XgBoost import XGBoostModel\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Info_2\n",
      "Product_Info_3\n",
      "Employment_Info_2\n",
      "InsuredInfo_3\n",
      "Medical_History_2\n",
      "Medical_History_10\n",
      "Scaling...\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')    \n",
    "\n",
    "train, _, labels = feature_generator.GetFeatures(dfTrain, dfTest, 10, True)\n",
    "metaFeatures = train.columns\n",
    "\n",
    "#GetFeatures currently modifies dfTest, need to re-create them\n",
    "dfTest = pd.read_csv('test.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StackingResults:\n",
    "    \n",
    "    def __init__(self, stackingModel, cutPoints, qwk):\n",
    "        self.stackingModel = stackingModel\n",
    "        self.cutPoints = cutPoints\n",
    "        self.qwk = qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateStackingResults(train_index, test_index, trainModelPredictions, testModelPredictions, featuresToUse):\n",
    "\n",
    "    xTrain = trainModelPredictions[featuresToUse].values\n",
    "    yTrain = labels.iloc[train_index]\n",
    "\n",
    "    eta_list = [0.05] * 250 \n",
    "    eta_list = eta_list + [0.02] * 450 \n",
    "    stackingModel = LinearRegression()\n",
    "    stackingModel.fit(xTrain, yTrain)\n",
    "\n",
    "    xTest = testModelPredictions[featuresToUse].values\n",
    "    yTest = labels.iloc[test_index]\n",
    "\n",
    "    trainPredictions = stackingModel.predict(xTrain)\n",
    "    predictions = stackingModel.predict(xTest)\n",
    "\n",
    "    cutPoints = None\n",
    "    cpo = CutPointOptimizer(trainPredictions, yTrain)\n",
    "    cutPoints = optimize.fmin(cpo.qwk, initialCutPoints)\n",
    "\n",
    "    trainPredictions = np.searchsorted(cutPoints, trainPredictions) + 1   \n",
    "    predictions = np.searchsorted(cutPoints, predictions) + 1   \n",
    "\n",
    "    testQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, yTest)\n",
    "    trainQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, yTrain)\n",
    " \n",
    "    print \"Test QWK: %s\\n\" % testQwk\n",
    "    print \"Train QWK: %s\\n\" % trainQwk\n",
    "    \n",
    "    return stackingModel, cutPoints, predictions, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetBestModel(modelsToUse, metaFeatures):\n",
    "    \n",
    "    K = 3\n",
    "    kf = KFold(len(train), K)\n",
    "    \n",
    "    bestQwk = -1\n",
    "        \n",
    "    meanTestQwk = 0\n",
    "    meanTrainQwk = 0\n",
    "    num = 1\n",
    "    resultList = list()\n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "        \n",
    "        frames = [pd.read_csv('fold%s.csv' % str(i)) for i in range(1, K+1) if i != num  ]\n",
    "        trainModelPredictions = pd.concat(frames)  \n",
    "        testModelPredictions = pd.read_csv('fold%s.csv' % str(num))\n",
    "    \n",
    "        features = list(modelsToUse)\n",
    "#         features = list()\n",
    "#         for model in modelsToUse:\n",
    "#             for metaFeature in metaFeatures:\n",
    "#                 feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "#                 features.append(feature)\n",
    "#                 trainModelPredictions[feature] = trainModelPredictions[model].values * train.iloc[train_index][metaFeature].values\n",
    "#                 testModelPredictions[feature] = testModelPredictions[model] * train.iloc[test_index][metaFeature].values\n",
    "        \n",
    "        stackingModel, cutPoints, predictions, YTest = calculateStackingResults(train_index, test_index, trainModelPredictions, testModelPredictions, features)        \n",
    "        overallTestQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, YTest)\n",
    "        \n",
    "        result = StackingResults(stackingModel, cutPoints, overallTestQwk) \n",
    "        resultList.append(result)    \n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CutPointOptimizer:\n",
    "    \n",
    "    def __init__(self, predicted, actual):\n",
    "        self.predicted = predicted\n",
    "        self.actual = actual\n",
    "\n",
    "    def qwk(self, cutPoints):\n",
    "        transformedPredictions = np.searchsorted(cutPoints, self.predicted) + 1            \n",
    "        return -1 * quadratic_weighted_kappa.quadratic_weighted_kappa(transformedPredictions, self.actual)\n",
    "\n",
    "initialCutPoints = np.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.658207\n",
      "         Iterations: 137\n",
      "         Function evaluations: 285\n",
      "Test QWK: 0.646614922878\n",
      "\n",
      "Train QWK: 0.658207145534\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.660980\n",
      "         Iterations: 175\n",
      "         Function evaluations: 331\n",
      "Test QWK: 0.656595602754\n",
      "\n",
      "Train QWK: 0.660979586119\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.651304\n",
      "         Iterations: 138\n",
      "         Function evaluations: 263\n",
      "Test QWK: 0.660876911873\n",
      "\n",
      "Train QWK: 0.651303726608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelsToUse = ['Keras', 'LogisticRegression', 'XGBoostRegLin', 'BaggingDescisionTrees_n_estimators=20', 'BaggingDescisionTreeClassifiers_n_estimators=20']\n",
    "# modelsToUse = ['XGBoostRegLin']\n",
    "#not using BaggingLinearRegression_n_estimators=10' currently\n",
    "# modelsToUse = ['Keras']\n",
    "# bestStackingModel, bestCutPoints, bestFold, _, _ = \n",
    "results = GetBestModel(modelsToUse, metaFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WritePredictionsToFile(results, modelsToUse, dfTest, fileName):\n",
    "               \n",
    "        predictions = np.zeros(len(dfTest))\n",
    "        \n",
    "        for i in range(1, len(results)+1):\n",
    "            X = pd.read_csv('testPredictions%s.csv' % str(i))[modelsToUse]\n",
    "            result = results[i-1]\n",
    "            print result.qwk\n",
    "            predictions += = result.qwk * (np.searchsorted(result.cutPoints, result.stackingModel.predict(X)) + 1)\n",
    "            \n",
    "        totalWeight = np.sum([result.qwk for result in results])\n",
    "        predictions /= totalWeight\n",
    "        \n",
    "        print predictions\n",
    "            \n",
    "        \n",
    "        predDf = pd.DataFrame()\n",
    "        predDf['Id'] = dfTest['Id']\n",
    "        predDf['Response'] = predictions\n",
    "        predDf['Response'] = predDf['Response'].astype(int)\n",
    "        print predDf['Response'].values\n",
    "        predDf.to_csv(path_or_buf=fileName, columns=['Id', 'Response'], index=False, header=['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['XGBoostLinear'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f487bd7b66c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWritePredictionsToFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelsToUse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'oldYoungcutPointsStacking.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestFold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-04a0928e5577>\u001b[0m in \u001b[0;36mWritePredictionsToFile\u001b[0;34m(results, modelsToUse, dfTest, fileName, bestFold)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mWritePredictionsToFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelsToUse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestFold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testPredictions%s.csv'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbestFold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelsToUse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcutPoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstackingModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1964\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1965\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2005\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['XGBoostLinear'] not in index\""
     ]
    }
   ],
   "source": [
    "WritePredictionsToFile(results, modelsToUse, dfTest, 'cutPointsStacking.csv', bestFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingDescisionTrees_n_estimators=20, BaggingLinearRegression_n_estimators=10, (0.82723223060018414, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, LogisticRegression, (0.71672697762552096, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoost, (0.90545269754757352, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostLinear, (0.82816721211796251, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras100/50Layers6Epochs, (0.81860775406944197, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras, (0.81700780178490495, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Index, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, IndexNum, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, LinXGBoost, (0.9073296629252775, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostKappa, (0.67522197855644062, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostRegLin, (0.91606803512950197, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, BaggingDescisionTreeClassifiers_n_estimators=20, (0.74292659153361496, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, LogisticRegression, (0.79257557312551052, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoost, (0.904850243234953, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostLinear, (0.99913140910352671, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras100/50Layers6Epochs, (0.92229682653105571, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras, (0.92010697919516937, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Index, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, IndexNum, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, LinXGBoost, (0.91019079106813661, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostKappa, (0.75564854859506869, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostRegLin, (0.90953350761334073, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68168961307299947, 0.0)\n",
      "LogisticRegression, XGBoost, (0.78209242227757947, 0.0)\n",
      "LogisticRegression, XGBoostLinear, (0.79283882656263416, 0.0)\n",
      "LogisticRegression, Keras100/50Layers6Epochs, (0.833530881516099, 0.0)\n",
      "LogisticRegression, Keras, (0.83357685317985819, 0.0)\n",
      "LogisticRegression, Index, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, IndexNum, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, LinXGBoost, (0.78290495298299478, 0.0)\n",
      "LogisticRegression, XGBoostKappa, (0.64366009561307713, 0.0)\n",
      "LogisticRegression, XGBoostRegLin, (0.78317345118762194, 0.0)\n",
      "LogisticRegression, BaggingDescisionTreeClassifiers_n_estimators=20, (0.61175842801347102, 0.0)\n",
      "XGBoost, XGBoostLinear, (0.90522784991976157, 0.0)\n",
      "XGBoost, Keras100/50Layers6Epochs, (0.88413515329574521, 0.0)\n",
      "XGBoost, Keras, (0.88171007365918852, 0.0)\n",
      "XGBoost, Index, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, IndexNum, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, LinXGBoost, (0.97609232514314026, 0.0)\n",
      "XGBoost, XGBoostKappa, (0.72140912158718817, 0.0)\n",
      "XGBoost, XGBoostRegLin, (0.97866581828483745, 0.0)\n",
      "XGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.73938416009873598, 0.0)\n",
      "XGBoostLinear, Keras100/50Layers6Epochs, (0.92278196779987209, 0.0)\n",
      "XGBoostLinear, Keras, (0.92073778661946493, 0.0)\n",
      "XGBoostLinear, Index, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, IndexNum, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, LinXGBoost, (0.91064005259907876, 0.0)\n",
      "XGBoostLinear, XGBoostKappa, (0.75595071266566749, 0.0)\n",
      "XGBoostLinear, XGBoostRegLin, (0.9100829960546285, 0.0)\n",
      "XGBoostLinear, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68283714571775789, 0.0)\n",
      "Keras100/50Layers6Epochs, Keras, (0.97983753409734264, 0.0)\n",
      "Keras100/50Layers6Epochs, Index, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, IndexNum, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, LinXGBoost, (0.88849761282823647, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostKappa, (0.72858524888847731, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostRegLin, (0.88935305062642545, 0.0)\n",
      "Keras100/50Layers6Epochs, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68761741035478674, 0.0)\n",
      "Keras, Index, (0.0052458432147417938, 0.46051311918970927)\n",
      "Keras, IndexNum, (0.0052458432147417938, 0.46051311918970927)\n",
      "Keras, LinXGBoost, (0.88665186404672836, 0.0)\n",
      "Keras, XGBoostKappa, (0.71584158281884491, 0.0)\n",
      "Keras, XGBoostRegLin, (0.88742191515977742, 0.0)\n",
      "Keras, BaggingDescisionTreeClassifiers_n_estimators=20, (0.68962923444072199, 0.0)\n",
      "Index, IndexNum, (1.0, 0.0)\n",
      "Index, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "Index, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "Index, XGBoostRegLin, (0.0034977943473489693, 0.62266339790674163)\n",
      "Index, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0083909695130439613, 0.23780880957531433)\n",
      "IndexNum, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "IndexNum, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "IndexNum, XGBoostRegLin, (0.0034977943473489693, 0.62266339790674163)\n",
      "IndexNum, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0083909695130439613, 0.23780880957531433)\n",
      "LinXGBoost, XGBoostKappa, (0.71681602052852855, 0.0)\n",
      "LinXGBoost, XGBoostRegLin, (0.98736729585750505, 0.0)\n",
      "LinXGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.74589105708046266, 0.0)\n",
      "XGBoostKappa, XGBoostRegLin, (0.72189611233226181, 0.0)\n",
      "XGBoostKappa, BaggingDescisionTreeClassifiers_n_estimators=20, (0.55518448655116126, 0.0)\n",
      "XGBoostRegLin, BaggingDescisionTreeClassifiers_n_estimators=20, (0.75098054134586678, 0.0)\n"
     ]
    }
   ],
   "source": [
    "fold1 = pd.read_csv('fold1.csv')\n",
    "\n",
    "for i in range(len(fold1.columns)):\n",
    "    for j in range(i + 1, len(fold1.columns)):        \n",
    "        print \"%s, %s, %s\" % (fold1.columns[i], fold1.columns[j], pearsonr(fold1[fold1.columns[i]], fold1[fold1.columns[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.85559797287\n",
      "0.641791045\n",
      "0.313432836\n",
      "5.04165243211\n"
     ]
    }
   ],
   "source": [
    "K=3\n",
    "num = 1\n",
    "frames = [pd.read_csv('fold%s.csv' % str(i)) for i in range(1, K+1) if i != num  ]\n",
    "testModelPredictions = pd.read_csv('fold%s.csv' % str(num))\n",
    "\n",
    "features = list()\n",
    "for model in modelsToUse:\n",
    "    for metaFeature in metaFeatures:\n",
    "        feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "        features.append(feature)\n",
    "        testModelPredictions[feature] = testModelPredictions[model] * dfTrain[metaFeature]\n",
    "        print foldDf[model][0]\n",
    "        print dfTrain[metaFeature][0]\n",
    "        print dfTrain[metaFeature][20000]\n",
    "        print testModelPredictions[feature][0]\n",
    "#         print testModelPredictions[feature][20000]\n",
    "#         print foldDf[model]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
