{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import feature_generator\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import optimize\n",
    "from XgBoost import XGBoostModel\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from CutPoints import CutPointOptimizer\n",
    "from NN import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Info_2\n",
      "Product_Info_3\n",
      "Employment_Info_2\n",
      "InsuredInfo_3\n",
      "Medical_History_2\n",
      "Medical_History_10\n",
      "Scaling...\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')    \n",
    "\n",
    "train, _, labels = feature_generator.GetFeatures(dfTrain, dfTest, 100, True)\n",
    "metaFeatures = train.columns\n",
    "\n",
    "#GetFeatures currently modifies dfTest, need to re-create them\n",
    "dfTest = pd.read_csv('test.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StackingResults:\n",
    "    \n",
    "    def __init__(self, stackingModel, cutPoints, qwk):\n",
    "        self.stackingModel = stackingModel\n",
    "        self.cutPoints = cutPoints\n",
    "        self.qwk = qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateStackingResults(xTrain, yTrain, xTest, yTest):\n",
    "    stackingModel = LinearRegression()\n",
    "    print xTrain.shape\n",
    "    stackingModel.fit(xTrain, yTrain)\n",
    "\n",
    "    trainPredictions = stackingModel.predict(xTrain)\n",
    "    predictions = stackingModel.predict(xTest)\n",
    "\n",
    "    initialCutPoints = np.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5])\n",
    "    cpo = CutPointOptimizer(trainPredictions, yTrain)\n",
    "    cutPoints = optimize.fmin(cpo.qwk, initialCutPoints)\n",
    "\n",
    "    trainPredictions = np.searchsorted(cutPoints, trainPredictions) + 1   \n",
    "    predictions = np.searchsorted(cutPoints, predictions) + 1   \n",
    "\n",
    "    testQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, yTest)\n",
    "    trainQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, yTrain)\n",
    " \n",
    "    print \"Test QWK: %s\\n\" % testQwk\n",
    "    print \"Train QWK: %s\\n\" % trainQwk\n",
    "    \n",
    "    return stackingModel, cutPoints, predictions, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetBestModel(modelsToUse, metaFeatures):\n",
    "    \n",
    "    K = 5\n",
    "    kf = KFold(len(train), K)\n",
    "    indices = [indices for indices in kf]\n",
    "    train_indices = [index[0] for index in indices]\n",
    "    test_indices = [index[1] for index in indices]\n",
    "        \n",
    "    meanTestQwk = 0\n",
    "    meanTrainQwk = 0\n",
    "    num = 1\n",
    "    resultList = list()\n",
    "\n",
    "    for i in range(1, K+1):\n",
    "        \n",
    "        trainFile = 'combinedTrainPredictions%s.csv' % str(num)\n",
    "        testFile = 'combinedTestPredictions%s.csv' % str(num)\n",
    "\n",
    "        trainDF = pd.read_csv(trainFile) if os.path.isfile(trainFile) else pd.DataFrame()  \n",
    "        testDF = pd.read_csv(testFile) if os.path.isfile(testFile) else pd.DataFrame()  \n",
    "    \n",
    "        features = list(modelsToUse)\n",
    "#         features = list()\n",
    "#         for j in range(len(modelsToUse)):\n",
    "#             for  k in range(len(modelsToUse)):\n",
    "#                 model1 = modelsToUse[j]\n",
    "#                 model2 = modelsToUse[k]\n",
    "#                 if model1 == model2:\n",
    "#                     continue\n",
    "#                 feature = 'Meta_%s_%s' % (model1, model2)\n",
    "#                 features.append(feature)\n",
    "#                 fold[feature] = fold[model1].values * fold[model2].values\n",
    " \n",
    "#         features = list()\n",
    "#         for model in modelsToUse:\n",
    "#             for metaFeature in metaFeatures:\n",
    "#                 feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "#                 features.append(feature)\n",
    "#                 fold[feature] = fold[model].values * train.iloc[test_indices[i-1]][metaFeature].values\n",
    "\n",
    "        stackingModel.fit(trainDF[features].values)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(fold[features].values, labels.iloc[test_indices[i-1]].values, test_size=0.20, random_state=0)\n",
    "        stackingModel, cutPoints, predictions, YTest = calculateStackingResults(X_train, y_train, X_test, y_test)        \n",
    "        overallTestQwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, YTest)\n",
    "        \n",
    "        result = StackingResults(stackingModel, cutPoints, overallTestQwk) \n",
    "        resultList.append(result)    \n",
    "            \n",
    "        num += 1\n",
    "\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15835, 2)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.648835\n",
      "         Iterations: 122\n",
      "         Function evaluations: 245\n",
      "Test QWK: 0.654457238067\n",
      "\n",
      "Train QWK: 0.648835025104\n",
      "\n",
      "(15835, 2)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.645496\n",
      "         Iterations: 94\n",
      "         Function evaluations: 214\n",
      "Test QWK: 0.627220698781\n",
      "\n",
      "Train QWK: 0.645495595143\n",
      "\n",
      "(15834, 2)\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.643087\n",
      "         Iterations: 105\n",
      "         Function evaluations: 227\n",
      "Test QWK: 0.666773629234\n",
      "\n",
      "Train QWK: 0.64308708728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelsToUse = ['Keras', 'BaggingLinearRegression_n_estimators=10', 'LogisticRegression', 'XGBoostRegLin', 'BaggingDescisionTrees_n_estimators=20', 'BaggingDescisionTreeClassifiers_n_estimators=20']\n",
    "# modelsToUse = ['XGBoostRegLin']\n",
    "#not using BaggingLinearRegression_n_estimators=10' currently\n",
    "# modelsToUse = ['Keras']\n",
    "# bestStackingModel, bestCutPoints, bestFold, _, _ = \n",
    "results = GetBestModel(modelsToUse, metaFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def WritePredictionsToFile(results, modelsToUse, dfTest, fileName):\n",
    "               \n",
    "        predictions = np.zeros(len(dfTest))\n",
    "        \n",
    "        for i in range(1, len(results)+1):\n",
    "            X = pd.read_csv('testPredictions%s.csv' % str(i))[modelsToUse]\n",
    "            result = results[i-1]\n",
    "            print result.qwk\n",
    "            predictions += result.qwk * (np.searchsorted(result.cutPoints, result.stackingModel.predict(X)) + 1)\n",
    "            \n",
    "        totalWeight = np.sum([result.qwk for result in results])\n",
    "        predictions /= totalWeight\n",
    "        print predictions\n",
    "        predictions = np.round(predictions).astype(int)\n",
    "            \n",
    "        \n",
    "        predDf = pd.DataFrame()\n",
    "        predDf['Id'] = dfTest['Id']\n",
    "        predDf['Response'] = predictions\n",
    "        print predDf['Response'].values\n",
    "        predDf.to_csv(path_or_buf=fileName, columns=['Id', 'Response'], index=False, header=['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WritePredictionsToFile(results, modelsToUse, dfTest, 'cutPointsStacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingDescisionTrees_n_estimators=20, BaggingLinearRegression_n_estimators=10, (0.82723223060018414, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, LogisticRegression, (0.71672697762552096, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoost, (0.90545269754757352, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostLinear, (0.82816721211796251, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras100/50Layers6Epochs, (0.81860775406944197, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Keras, (0.81871121498888999, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, Index, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, IndexNum, (0.0040305074970553995, 0.57069839828140645)\n",
      "BaggingDescisionTrees_n_estimators=20, LinXGBoost, (0.9073296629252775, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostKappa, (0.67522197855644062, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, XGBoostRegLin, (0.92200272332950317, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, BaggingDescisionTreeClassifiers_n_estimators=20, (0.77819061769523235, 0.0)\n",
      "BaggingDescisionTrees_n_estimators=20, RandomForest, (0.8986190249109739, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, LogisticRegression, (0.79257557312551052, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoost, (0.904850243234953, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostLinear, (0.99913140910352671, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras100/50Layers6Epochs, (0.92229682653105571, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Keras, (0.91601007783567634, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, Index, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, IndexNum, (0.0055956913467662961, 0.43115268067810208)\n",
      "BaggingLinearRegression_n_estimators=10, LinXGBoost, (0.91019079106813661, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostKappa, (0.75564854859506869, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, XGBoostRegLin, (0.90355853820409449, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, BaggingDescisionTreeClassifiers_n_estimators=20, (0.71667101250387077, 0.0)\n",
      "BaggingLinearRegression_n_estimators=10, RandomForest, (0.82781026369391719, 0.0)\n",
      "LogisticRegression, XGBoost, (0.78209242227757947, 0.0)\n",
      "LogisticRegression, XGBoostLinear, (0.79283882656263416, 0.0)\n",
      "LogisticRegression, Keras100/50Layers6Epochs, (0.833530881516099, 0.0)\n",
      "LogisticRegression, Keras, (0.83064301935488838, 0.0)\n",
      "LogisticRegression, Index, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, IndexNum, (0.0061578070910766249, 0.38632431300353376)\n",
      "LogisticRegression, LinXGBoost, (0.78290495298299478, 0.0)\n",
      "LogisticRegression, XGBoostKappa, (0.64366009561307713, 0.0)\n",
      "LogisticRegression, XGBoostRegLin, (0.7807181484847906, 0.0)\n",
      "LogisticRegression, BaggingDescisionTreeClassifiers_n_estimators=20, (0.65490225853525297, 0.0)\n",
      "LogisticRegression, RandomForest, (0.72529375326510259, 0.0)\n",
      "XGBoost, XGBoostLinear, (0.90522784991976157, 0.0)\n",
      "XGBoost, Keras100/50Layers6Epochs, (0.88413515329574521, 0.0)\n",
      "XGBoost, Keras, (0.88183468215258154, 0.0)\n",
      "XGBoost, Index, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, IndexNum, (0.0046425711848201365, 0.51367185803061144)\n",
      "XGBoost, LinXGBoost, (0.97609232514314026, 0.0)\n",
      "XGBoost, XGBoostKappa, (0.72140912158718817, 0.0)\n",
      "XGBoost, XGBoostRegLin, (0.97604277657778449, 0.0)\n",
      "XGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.77663767628151636, 0.0)\n",
      "XGBoost, RandomForest, (0.89345458772361097, 0.0)\n",
      "XGBoostLinear, Keras100/50Layers6Epochs, (0.92278196779987209, 0.0)\n",
      "XGBoostLinear, Keras, (0.91636269234433376, 0.0)\n",
      "XGBoostLinear, Index, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, IndexNum, (0.0058243239060255568, 0.41256620003132816)\n",
      "XGBoostLinear, LinXGBoost, (0.91064005259907876, 0.0)\n",
      "XGBoostLinear, XGBoostKappa, (0.75595071266566749, 0.0)\n",
      "XGBoostLinear, XGBoostRegLin, (0.90417732670236395, 0.0)\n",
      "XGBoostLinear, BaggingDescisionTreeClassifiers_n_estimators=20, (0.71770300569554357, 0.0)\n",
      "XGBoostLinear, RandomForest, (0.82984633143240139, 0.0)\n",
      "Keras100/50Layers6Epochs, Keras, (0.98149472800263593, 0.0)\n",
      "Keras100/50Layers6Epochs, Index, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, IndexNum, (0.0047123529567832043, 0.50736374736749357)\n",
      "Keras100/50Layers6Epochs, LinXGBoost, (0.88849761282823647, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostKappa, (0.72858524888847731, 0.0)\n",
      "Keras100/50Layers6Epochs, XGBoostRegLin, (0.88553065832470346, 0.0)\n",
      "Keras100/50Layers6Epochs, BaggingDescisionTreeClassifiers_n_estimators=20, (0.73176737302089578, 0.0)\n",
      "Keras100/50Layers6Epochs, RandomForest, (0.83319628217686592, 0.0)\n",
      "Keras, Index, (0.0068217266413278218, 0.33720263466399214)\n",
      "Keras, IndexNum, (0.0068217266413278218, 0.33720263466399214)\n",
      "Keras, LinXGBoost, (0.88586608425907853, 0.0)\n",
      "Keras, XGBoostKappa, (0.72773031630226181, 0.0)\n",
      "Keras, XGBoostRegLin, (0.88429221506739419, 0.0)\n",
      "Keras, BaggingDescisionTreeClassifiers_n_estimators=20, (0.73310866826493193, 0.0)\n",
      "Keras, RandomForest, (0.83435865610581206, 0.0)\n",
      "Index, IndexNum, (1.0, 0.0)\n",
      "Index, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "Index, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "Index, XGBoostRegLin, (0.0040601245054549982, 0.56787094405407501)\n",
      "Index, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0011208836777270139, 0.87470225853195649)\n",
      "Index, RandomForest, (0.0024844745285194981, 0.72669742273045124)\n",
      "IndexNum, LinXGBoost, (0.0043369441982704414, 0.54177304103800372)\n",
      "IndexNum, XGBoostKappa, (0.0037508172275127578, 0.59772470336261696)\n",
      "IndexNum, XGBoostRegLin, (0.0040601245054549982, 0.56787094405407501)\n",
      "IndexNum, BaggingDescisionTreeClassifiers_n_estimators=20, (0.0011208836777270139, 0.87470225853195649)\n",
      "IndexNum, RandomForest, (0.0024844745285194981, 0.72669742273045124)\n",
      "LinXGBoost, XGBoostKappa, (0.71681602052852855, 0.0)\n",
      "LinXGBoost, XGBoostRegLin, (0.98306080812653995, 0.0)\n",
      "LinXGBoost, BaggingDescisionTreeClassifiers_n_estimators=20, (0.78634997077555213, 0.0)\n",
      "LinXGBoost, RandomForest, (0.90333812700398264, 0.0)\n",
      "XGBoostKappa, XGBoostRegLin, (0.722150434991219, 0.0)\n",
      "XGBoostKappa, BaggingDescisionTreeClassifiers_n_estimators=20, (0.57747594376228339, 0.0)\n",
      "XGBoostKappa, RandomForest, (0.65968256070651277, 0.0)\n",
      "XGBoostRegLin, BaggingDescisionTreeClassifiers_n_estimators=20, (0.7956354033522538, 0.0)\n",
      "XGBoostRegLin, RandomForest, (0.91076522365083146, 0.0)\n",
      "BaggingDescisionTreeClassifiers_n_estimators=20, RandomForest, (0.80248895752254745, 0.0)\n"
     ]
    }
   ],
   "source": [
    "fold1 = pd.read_csv('fold1.csv')\n",
    "\n",
    "for i in range(len(fold1.columns)):\n",
    "    for j in range(i + 1, len(fold1.columns)):        \n",
    "        print \"%s, %s, %s\" % (fold1.columns[i], fold1.columns[j], pearsonr(fold1[fold1.columns[i]], fold1[fold1.columns[j]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K=3\n",
    "num = 1\n",
    "frames = [pd.read_csv('fold%s.csv' % str(i)) for i in range(1, K+1) if i != num  ]\n",
    "testModelPredictions = pd.read_csv('fold%s.csv' % str(num))\n",
    "\n",
    "features = list()\n",
    "for model in modelsToUse:\n",
    "    for metaFeature in metaFeatures:\n",
    "        feature = 'Meta_%s_%s' % (model, metaFeature)\n",
    "        features.append(feature)\n",
    "        testModelPredictions[feature] = testModelPredictions[model] * dfTrain[metaFeature]\n",
    "        print foldDf[model][0]\n",
    "        print dfTrain[metaFeature][0]\n",
    "        print dfTrain[metaFeature][20000]\n",
    "        print testModelPredictions[feature][0]\n",
    "#         print testModelPredictions[feature][20000]\n",
    "#         print foldDf[model]\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
