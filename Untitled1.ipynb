{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import feature_generator\n",
    "import xgboost as xgb\n",
    "from scipy import optimize\n",
    "import os.path\n",
    "from NN import NN\n",
    "from XgBoost import XGBoostModel\n",
    "from sklearn.linear_model import Ridge\n",
    "from CutPoints import CutPointOptimizer\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')    \n",
    "\n",
    "# dfTrain = dfTrain.drop('Age_BMI', 1)\n",
    "# dfTest = dfTest.drop('Age_BMI', 1)\n",
    "# dfTrain['Age_BMI'] = dfTrain['Ins_Age'] * dfTrain['BMI']\n",
    "# dfTest['Age_BMI'] = dfTest['Ins_Age'] * dfTest['BMI']\n",
    "\n",
    "dfTrain['Product_Info_2_char'] = dfTrain[\"Product_Info_2\"].str[0]\n",
    "dfTrain['Product_Info_2_num'] = dfTrain[\"Product_Info_2\"].str[1]\n",
    "\n",
    "dfTest['Product_Info_2_char'] = dfTest[\"Product_Info_2\"].str[0]\n",
    "dfTest['Product_Info_2_num'] = dfTest[\"Product_Info_2\"].str[1]\n",
    "\n",
    "dfTrain.to_csv(path_or_buf='train.csv', index=False)\n",
    "dfTest.to_csv(path_or_buf='test.csv', index=False)\n",
    "\n",
    "# train, test, labels = feature_generator.GetFeatures(dfTrain, dfTest, 10000, False)\n",
    "# featureImpDf = pd.read_csv('FeatureImportance.csv')\n",
    "# dfTrain = pd.read_csv('train.csv')\n",
    "# dfTest = pd.read_csv('test.csv')  \n",
    "# importantFeatures = featureImpDf[featureImpDf['Importance'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainNanSum = dfTrain.isnull().sum(axis=1)\n",
    "testNanSum = dfTest.isnull().sum(axis=1)\n",
    "\n",
    "dfTrain['NanSum'] = trainNanSum\n",
    "dfTest['NanSum'] = testNanSum\n",
    "\n",
    "dfTrain.to_csv(path_or_buf='train.csv', index=False)\n",
    "dfTest.to_csv(path_or_buf='test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fiveFeatures = importantFeatures[importantFeatures.Importance > 11]\n",
    "# print len(fiveFeatures)\n",
    "\n",
    "# numericalVars = ['Product_Info_4', 'Ins_Age', 'Ht', 'Wt', 'BMI', 'Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Good_Medical_Keyword_Total', 'Medical_History_1', 'Medical_History_15', 'Medical_History_24', 'Medical_History_32']\n",
    "# missingDataColumns = [var for var in numericalVars if dfTrain[var].isnull().sum() > 0]\n",
    "# miss = pd.DataFrame()\n",
    "# for col in missingDataColumns:\n",
    "#     miss[col] = dfTrain[col].isnull()\n",
    "# print miss\n",
    "overallMean = np.mean(labels)\n",
    "dfTrain['Med_History_2_Occ'] = np.NAN\n",
    "dfTest['Med_History_2_Occ'] = np.NAN\n",
    "\n",
    "for val in dfTrain[\"Medical_History_2\"].unique():\n",
    "    rowsWithVal = dfTrain[dfTrain[\"Medical_History_2\"] == val]   \n",
    "#     if len(rowsWithVal) > 10:\n",
    "    dfTrain.loc[dfTrain[\"Medical_History_2\"] == val, 'Med_History_2_Occ'] = len(rowsWithVal)\n",
    "\n",
    "for val in dfTest[\"Medical_History_2\"].unique():\n",
    "    rowsWithVal = dfTrain[dfTrain[\"Medical_History_2\"] == val]\n",
    "#     if len(rowsWithVal) > 10:\n",
    "    dfTest.loc[dfTest[\"Medical_History_2\"] == val, 'Med_History_2_Response'] = len(rowsWithVal)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print quadratic_weighted_kappa.quadratic_weighted_kappa(dfTrain['Med_History_2_Response'], labels) \n",
    "# print dfTrain['Med_History_2_Response'].isnull().sum()\n",
    "print dfTest['Med_History_2_Response'].isnull().sum()\n",
    "print dfTest['Med_History_2_Response'].notnull().sum()\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print pearsonr(dfTrain['Med_History_2_Occ'], labels)\n",
    "# print dfTrain['Med_History_2_Response'] \n",
    "# neigh = NearestNeighbors(n_neighbors=3, metric='cosine', algorithm='brute')\n",
    "# neigh.fit(continTrain)\n",
    "# pwise = neigh.kneighbors(continTrain)\n",
    "# pwise = pairwise_distances(continTrain, , metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = 2\n",
    "kf = KFold(len(train), folds)\n",
    "qwks = list()\n",
    "\n",
    "nearestNeighborsMissing = np.zeros(len(miss))\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "\n",
    "    trainData = dfTrain.iloc[train_index]\n",
    "    testData = dfTrain.iloc[test_index]\n",
    "    for val in trainData[\"Medical_History_2\"].unique():\n",
    "        testRowsWithVal = testData[testData[\"Medical_History_2\"] == val]   \n",
    "        testData.loc[testData[\"Medical_History_2\"] == val] = testData['Response'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kf = KFold(len(train), folds)\n",
    "qwks = list()\n",
    "\n",
    "nearestNeighborsMissing = np.zeros(len(miss))\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "\n",
    "#     trainData = dfTrain.iloc[train_index]\n",
    "#     testData = dfTrain.iloc[test_index]\n",
    "#     for val in trainData[\"Medical_History_2\"].unique():\n",
    "#         testRowsWithVal = testData[testData[\"Medical_History_2\"] == val]   \n",
    "#         testData.loc[trainData[\"Medical_History_2\"] == val] = rowsWithVal['Response'].mean() \n",
    "    \n",
    "# dfTrain[dfTrain[\"Medical_History_2\"] == val]['Med_History_2_Response'] = dfTrain[dfTrain[\"Medical_History_2\"] == val]['Response'].\n",
    "    \n",
    "    neigh = KNeighborsRegressor(n_neighbors=10, metric='manhattan', weights='distance')\n",
    "    neigh.fit(dfTrain.iloc[train_index]['Med_History_2_Response'].values, labels.iloc[train_index])\n",
    "    predictions = neigh.predict(dfTrain.iloc[test_index]['Med_History_2_Response'].values )\n",
    "    \n",
    "    qwk = quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, labels.iloc[test_index])\n",
    "    nearestNeighborsMissing[test_index] = predictions\n",
    "    print qwk\n",
    "    qwks.append(qwk)\n",
    "    \n",
    "print \"mean %s\" % str(np.mean(qwks))\n",
    "print \"median %s\" % str(np.median(qwks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors=10, metric='manhattan', weights='distance')\n",
    "neigh.fit(miss, labels)\n",
    "testNeighborPredictions = neigh.predict(test[missingDataColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "bad = 0\n",
    "good = 0\n",
    "\n",
    "medKeyWordColumns = list()\n",
    "for column in dfTrain.columns:\n",
    "    if \"Medical_Keyword\" not in column:\n",
    "        continue\n",
    "\n",
    "    pearson = pearsonr(dfTrain[column], dfTrain.Response)\n",
    "    if pearson[1] > 0.05:\n",
    "        continue\n",
    "    val = pearson[0]\n",
    "    if val > 0:\n",
    "        bad +=1\n",
    "    else:\n",
    "        medKeyWordColumns.append(column)       \n",
    "        good +=1\n",
    "        \n",
    "print good\n",
    "print bad\n",
    "# print pearsonr(dfTrain[dfTrain[column].notnull()][column], dfTrain[dfTrain[column].notnull()].Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dfTrain['Medi'] = dfTrain['Ins_Age'] * dfTrain['BMI']\n",
    "dfTrain.to_csv(path_or_buf='train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dfTest['Age_BMI'] = dfTest['Ins_Age'] * dfTest['BMI']\n",
    "dfTest.to_csv(path_or_buf='test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "fakeBmi =(dfTrain['Wt'] + 0.000000001) / ((dfTrain['Ht'] ** 2) + 0.000000001)\n",
    "fakeBmi = (fakeBmi - np.min(fakeBmi)) / (np.max(fakeBmi) - np.min(fakeBmi)) \n",
    "\n",
    "print pearsonr(fakeBmi, dfTrain['BMI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateSyntheticBmi(df):\n",
    "\n",
    "    unNormalizedWeight = df['Wt'] * (158-40) + 40\n",
    "    unNormalizedHeight = df['Ht'] * (216-125) + 125\n",
    "    fakeBmi = unNormalizedWeight / (unNormalizedHeight ** 2)\n",
    "\n",
    "    print pearsonr(fakeBmi, df['BMI'])\n",
    "    \n",
    "    heightToGain = np.sqrt(2*unNormalizedWeight) - unNormalizedHeight\n",
    "    weightToGain = 0.5 * (unNormalizedHeight ** 2) - unNormalizedWeight\n",
    "    \n",
    "    df['HeightToGain'] = heightToGain\n",
    "    df['WeightToGain'] = weightToGain\n",
    "    \n",
    "calculateSyntheticBmi(dfTrain)\n",
    "calculateSyntheticBmi(dfTest)\n",
    "\n",
    "dfTrain.to_csv(path_or_buf='train.csv', index=False)\n",
    "dfTest.to_csv(path_or_buf='test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geneticAlgo = pd.read_csv('gptest.csv')\n",
    "boostAlgo = pd.read_csv('XgBoost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 6 ..., 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "predDf = pd.DataFrame()\n",
    "predDf['Id'] = dfTest['Id']\n",
    "predDf['Response'] = np.round((geneticAlgo['Response'] + boostAlgo['Response']) / 2).astype(int)\n",
    "print predDf['Response'].values\n",
    "predDf.to_csv(path_or_buf='AverageGeneticBoost.csv', columns=['Id', 'Response'], index=False, header=['Id', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "# import pandas as pd\n",
    "\n",
    "# class GeneticAlgoModel():\n",
    "    \n",
    "#     def fit(X, Y):\n",
    "#         pass\n",
    "    \n",
    "#     def predict(X):\n",
    "#         df = pd.read_csv('gptrain.csv')\n",
    "#         return df['Prediction'].values\n",
    "        \n",
    "# model = GeneticAlgoModel()\n",
    "\n",
    "kf = KFold(len(dfTrain), 8)\n",
    "\n",
    "for train_index, test_index in kf:\n",
    "    \n",
    "    combinedModel = CombinedModel([], [XGBoostModel(800, 7, 0.025, 0.50, 25)])\n",
    "#     combinedModel = CombinedModel(['XGBoost'], [])\n",
    "    \n",
    "    trainFile = 'combinedTrainPredictions%s.csv' % str(num)\n",
    "    validateFile = 'combinedValidatePredictions%s.csv' % str(num)\n",
    "    \n",
    "    trainDf = pd.read_csv('gptrain.csv')\n",
    "    testDf = pd.read_csv('gptest.csv')\n",
    "    \n",
    "    trainFold = pd.read_csv(trainFile)\n",
    "    trainFold['Genetic']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
