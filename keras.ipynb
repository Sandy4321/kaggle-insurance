{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import quadratic_weighted_kappa\n",
    "from sklearn.cross_validation import KFold\n",
    "import feature_generator\n",
    "import os.path\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from NN import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical_History_2\n",
      "Medical_History_10\n",
      "Scaling...\n"
     ]
    }
   ],
   "source": [
    "dfTrain = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')\n",
    "train, test, labels = feature_generator.make_dataset(True, \"mean\", True, dfTrain, dfTest)\n",
    "# train, test, labels = feature_generator.GetFeatures(dfTrain, dfTest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Input shape: 327\n",
      "Adding Layer 0: 40\n",
      "Adding sigmoid layer\n",
      "Adding 0.5 dropout\n",
      "Adding Layer 1: 10\n",
      "Adding sigmoid layer\n",
      "Adding 0.5 dropout\n",
      "Epoch 1/8\n",
      "53442/53442 [==============================] - 3s - loss: 2.2221     \n",
      "Epoch 2/8\n",
      "53442/53442 [==============================] - 3s - loss: 1.6354     \n",
      "Epoch 3/8\n",
      "53442/53442 [==============================] - 3s - loss: 1.4788     \n",
      "Epoch 4/8\n",
      "53442/53442 [==============================] - 3s - loss: 1.4372     \n",
      "Epoch 5/8\n",
      "53442/53442 [==============================] - 3s - loss: 1.4352     \n",
      "Epoch 6/8\n",
      "53442/53442 [==============================] - 4s - loss: 1.4265     \n",
      "Epoch 7/8\n",
      "53442/53442 [==============================] - 4s - loss: 1.4227     \n",
      "Epoch 8/8\n",
      "53442/53442 [==============================] - 3s - loss: 1.4138     \n",
      "5939/5939 [==============================] - 0s     \n",
      "53442/53442 [==============================] - 0s     \n",
      "0.579373946178\n",
      "0.591951985628\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating dataset...\") \n",
    "modelName = 'Keras100/50Layers6Epochs'\n",
    "kf = KFold(len(dfTrain), 3)\n",
    "num = 1\n",
    "num_inputs = train.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train.values, labels, test_size=0.10, random_state=0)\n",
    "\n",
    "clf = NN(inputShape = num_inputs, layers = [40, 10], dropout = [0.5, 0.5], activation='sigmoid', loss='mae', optimizer = 'adadelta', init = 'glorot_normal', nb_epochs = 8)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = np.clip(clf.predict(X_test), 1, 8)\n",
    "trainPredictions = np.clip(clf.predict(X_train), 1, 8)\n",
    "\n",
    "print quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, y_test)\n",
    "print quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, y_train)\n",
    "\n",
    "# for train_index, test_index in kf:\n",
    "\n",
    "#     predictionsDF = pd.read_csv('fold%s.csv' % str(num))    \n",
    "# #     xTrain = dfTrain.iloc[train_index][features].values\n",
    "# #     yTrain = dfTrain.iloc[train_index]['Response'].values \n",
    "    \n",
    "#     xTrain = train.iloc[train_index].values\n",
    "#     yTrain = labels.iloc[train_index].values \n",
    "#     clf.fit(xTrain, yTrain)\n",
    "\n",
    "#     xValidate = train.iloc[test_index].values\n",
    "#     yValidate = labels.iloc[test_index]\n",
    "#     predictions = np.clip(clf.predict(xValidate), 1, 8)\n",
    "# #     predictions = np.clip(clf.predict(train.values), 1, 8)\n",
    "#     trainPredictions = np.clip(clf.predict(xTrain), 1, 8)\n",
    "\n",
    "#     print quadratic_weighted_kappa.quadratic_weighted_kappa(predictions, yValidate)\n",
    "#     print quadratic_weighted_kappa.quadratic_weighted_kappa(trainPredictions, yTrain)\n",
    "    \n",
    "#     predictionsDF[modelName] = predictions\n",
    "#     predictionsDF.to_csv(path_or_buf='fold%s.csv' % str(num), index=False)\n",
    "    \n",
    "    \n",
    "#     predictionsFile = 'testPredictions%s.csv' % str(num)\n",
    "#     if os.path.isfile(predictionsFile):\n",
    "#         testDF = pd.read_csv(predictionsFile)   \n",
    "#     else:\n",
    "#         testDF = pd.DataFrame()\n",
    "\n",
    "#     xTest = test.values\n",
    "#     testPredictions = clf.predict(xTest)\n",
    "#     testDF[modelName] = testPredictions\n",
    "#     testDF.to_csv(path_or_buf=predictionsFile, index=False)\n",
    "    \n",
    "#     num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print labels.iloc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
